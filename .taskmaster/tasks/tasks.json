{
  "master": {
    "tasks": [
      {
        "id": 1,
        "title": "Enhance AuthDialog for OpenRouter API Key Prompt",
        "description": "Modify AuthDialog.tsx to prompt for OpenRouter API key when selected, ensuring secure handling and environment/config storage.",
        "details": "Update /packages/cli/src/ui/components/AuthDialog.tsx to include a prompt for OpenRouter API key input. Use secure input handling (e.g., masking). Store the API key in environment variables or a secure config file (e.g., dotenv for Node.js, or a custom encrypted config). Check for existing API keys in environment variables and skip prompt if present. Use react-hook-form for form state management (v7+).",
        "testStrategy": "Test that the prompt appears only for OpenRouter selection. Verify API key is stored securely and not logged. Test environment variable override. Manual and automated UI tests.",
        "priority": "high",
        "dependencies": [],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 2,
        "title": "Implement API Key Validation and Error Handling",
        "description": "Add logic to validate OpenRouter API keys and provide user feedback for invalid or missing keys.",
        "details": "In /packages/cli/src/ui/hooks/useAuthCommand.ts, implement API key validation by making a test request to OpenRouter (e.g., GET /api/keys endpoint). Use axios (v1.6+) for HTTP requests. Display clear error messages for invalid or missing keys. Handle rate limits and API errors gracefully. Store validated API key securely.",
        "testStrategy": "Test with valid, invalid, and missing API keys. Verify error messages and graceful handling. Automated integration tests for API key validation.",
        "priority": "high",
        "dependencies": [
          1
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 3,
        "title": "Add Model Listing and Selection UI",
        "description": "Implement UI to list available OpenRouter models and allow user selection, consistent with existing auth patterns.",
        "details": "Extend AuthDialog.tsx or create a new ModelSelection component to list models fetched from OpenRouter (GET /api/models). Use react-select (v5+) for dropdown. Save selected model in state and config. Ensure UI matches existing sprtscltr patterns. Use react-query (v4+) for data fetching and caching.",
        "testStrategy": "Test model listing and selection. Verify UI consistency. Manual and automated UI tests.",
        "priority": "medium",
        "dependencies": [
          2
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Fetch available models from OpenRouter API using react-query",
            "description": "Implement data fetching logic to retrieve available models from the OpenRouter API, utilizing react-query for caching and state management. Ensure the query key includes relevant parameters such as baseUrl for proper cache invalidation.",
            "dependencies": [],
            "details": "Use the useOpenRouterModelProviders hook or similar, passing the custom baseUrl from user configuration. Ensure the queryKey includes baseUrl as part of its key for correct caching and refetching when the endpoint changes.\n<info added on 2025-07-08T05:29:52.661Z>\nPlan update:\n- Implement a fetchModels method within OpenRouterContentGenerator to retrieve available models from the configured endpoint.\n- Create a useOpenRouterModels hook that uses fetchModels to fetch and locally cache the model list, ensuring efficient reuse and updates when the baseUrl changes.\n- Refactor ModelSelector to consume the models provided by useOpenRouterModels instead of relying on hardcoded values.\n- Add logic to ModelSelector to display loading indicators while fetching and handle error states gracefully if model retrieval fails.\n</info added on 2025-07-08T05:29:52.661Z>\n<info added on 2025-07-08T05:31:25.764Z>\nCreated fetchModels method in OpenRouterContentGenerator to retrieve models from the /api/v1/models endpoint using the configured baseUrl. Developed useOpenRouterModels React hook with a 5-minute cache TTL and integrated error handling. Updated ModelSelector to consume the dynamic model list from useOpenRouterModels, replacing the previous hardcoded values. Implemented loading indicators and error state handling in ModelSelector to improve user experience during model retrieval.\n</info added on 2025-07-08T05:31:25.764Z>",
            "status": "done",
            "testStrategy": ""
          },
          {
            "id": 2,
            "title": "Implement or extend ModelSelection component",
            "description": "Create a new ModelSelection component or extend the existing AuthDialog.tsx to include model selection functionality, integrating the data fetched in the previous step.",
            "dependencies": [
              1
            ],
            "details": "Ensure the component receives the list of models as props or via hook, and is structured to allow for easy integration of a dropdown UI.\n<info added on 2025-07-08T05:34:52.821Z>\nIntegrated the ModelSelector component into the main App.tsx rendering flow, utilizing the useModelSelector hook for managing model selection state. Implemented a /model slash command that triggers the model selector UI, which is only accessible when authenticated with OpenRouter. Ensured all components are properly connected with state management so that the model selector appears dynamically upon typing the /model command.\n</info added on 2025-07-08T05:34:52.821Z>",
            "status": "done",
            "testStrategy": ""
          },
          {
            "id": 3,
            "title": "Integrate react-select (v5+) for dropdown UI",
            "description": "Replace or enhance the model selection UI with react-select (v5+) to provide a user-friendly dropdown for model selection.",
            "dependencies": [
              2
            ],
            "details": "Configure react-select with the fetched model data, ensuring accessibility and usability. Style the dropdown to match existing UI patterns.\n<info added on 2025-07-08T05:38:46.371Z>\nRadioButtonSelect will be retained for model selection to maintain UI consistency with other dialogs (AuthDialog, ThemeDialog, EditorDialog). The ModelSelector component already provides a dropdown interface with loading, error, and keyboard accessibility features. Introducing react-select is unnecessary and would disrupt the established UI pattern while adding extra dependencies.\n</info added on 2025-07-08T05:38:46.371Z>",
            "status": "done",
            "testStrategy": ""
          },
          {
            "id": 4,
            "title": "Persist selected model in state and config",
            "description": "Ensure that the user's selected model is persisted both in component state and in the application's configuration, so it remains consistent across sessions and reloads.",
            "dependencies": [
              3
            ],
            "details": "Update state management logic to store the selected model, and synchronize with user configuration or context as appropriate.\n<info added on 2025-07-08T05:39:55.856Z>\nThe selected model is currently persisted for the session using config.setModel() within handleModelSelect, aligning with the established pattern where model selection is determined by environment variables (OPENROUTER_MODEL) or defaults. Persisting the selection across sessions would require writing to settings.json, but this is not implemented as it would diverge from the current approach. No changes to cross-session persistence are needed unless the requirements change.\n</info added on 2025-07-08T05:39:55.856Z>",
            "status": "done",
            "testStrategy": ""
          },
          {
            "id": 5,
            "title": "Ensure UI consistency and write UI tests",
            "description": "Review the implementation for consistency with sprtscltr UI patterns and write both manual and automated UI tests to verify correct behavior and appearance.",
            "dependencies": [
              4
            ],
            "details": "Perform visual and functional checks, update styles as needed, and implement tests using the project's preferred testing framework.\n<info added on 2025-07-08T05:41:35.873Z>\nUI consistency has been ensured by standardizing on the RadioButtonSelect component, mirroring patterns from AuthDialog, ThemeDialog, and EditorDialog, and implementing loading spinners, error states, and keyboard navigation (Enter to select, Escape to cancel). Styling uses Colors constants for visual alignment. Tests have been written for ModelSelector, useOpenRouterModels, and useModelSelector, following project conventions, though dependency issues currently prevent execution.\n</info added on 2025-07-08T05:41:35.873Z>",
            "status": "done",
            "testStrategy": ""
          }
        ]
      },
      {
        "id": 4,
        "title": "Enable Model Switching and Persistence",
        "description": "Model switching is already implemented: users can switch models mid-session using the /model command, and the model is persisted for the current session via config.setModel(). The UI displays a model change notification. The implementation follows the existing pattern where the model is determined by environment variables. Cross-session persistence (e.g., saving to settings.json) is not implemented, as this would deviate from the current architecture where auth-related settings come from environment variables.",
        "status": "done",
        "dependencies": [
          3
        ],
        "priority": "medium",
        "details": "No further changes are required for mid-session model switching or session persistence. Cross-session persistence (saving model preference to settings.json) is not implemented to maintain consistency with the current architecture, which relies on environment variables for auth and model configuration. Document this architectural decision and ensure user documentation reflects the current behavior and limitations.",
        "testStrategy": "Verify that users can switch models mid-session using the /model command and that the selected model persists for the duration of the session. Confirm that the UI displays a notification when the model changes. Automated integration tests should cover these behaviors. No tests are required for cross-session persistence, as it is not supported.",
        "subtasks": [
          {
            "id": 1,
            "title": "Document current model switching and persistence behavior",
            "description": "Update user and developer documentation to clarify that model switching is supported mid-session and persists for the session, but cross-session persistence is not implemented due to architectural constraints.",
            "status": "done",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 2,
            "title": "Add automated integration tests for model switching and session persistence",
            "description": "Ensure tests cover switching models with /model command, session persistence, and UI notifications. No tests for cross-session persistence are needed.",
            "status": "done",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          }
        ]
      },
      {
        "id": 5,
        "title": "Display Current Model in UI",
        "description": "Show the currently selected OpenRouter model in the status bar or header.",
        "details": "Update /packages/cli/src/ui/App.tsx to display the current model. Use context or state management (e.g., Zustand v4+ or React Context) to share model state across components. Ensure display updates on model switch.",
        "testStrategy": "Test that current model is displayed and updates on switch. Manual and automated UI tests.",
        "priority": "medium",
        "dependencies": [
          4
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 6,
        "title": "Ensure Backward Compatibility and Provider Consistency",
        "description": "Maintain compatibility with existing auth methods and ensure custom API providers follow the same pattern.",
        "details": "Review and update all auth and model selection flows to ensure backward compatibility. Apply the same model switching pattern to other providers if supported. Use TypeScript for type safety. Document changes and update configuration schema.",
        "testStrategy": "Test all auth methods and providers. Verify backward compatibility and consistent behavior. Automated integration and regression tests.",
        "priority": "medium",
        "dependencies": [
          5
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 7,
        "title": "Fix OpenRouter/DeepSeek Streaming Output Issue",
        "description": "Resolve the issue where the response is being built character by character, causing repeated text in the streaming output from OpenRouter/DeepSeek API.",
        "details": "To address this issue, implement the following steps: \n1. **Review API Request Structure**: Ensure that the API request to OpenRouter/DeepSeek is correctly formatted to handle streaming responses. This may involve setting the `stream` parameter to `true` in the API call, as shown in the DeepSeek API documentation[1]. \n2. **Buffering and Response Handling**: Implement a buffering mechanism to collect the streaming response in chunks rather than processing it character by character. This can be achieved using a library like `async-iterator` in Node.js or similar constructs in other languages. \n3. **Error Handling and Logging**: Enhance error handling to detect and log any issues that might cause repeated text, such as network errors or API rate limits. Use logging libraries to track these events for debugging purposes. \n4. **Testing with Different Models**: Test the streaming functionality with various models available through OpenRouter to ensure the fix is model-agnostic. \n5. **Code Refactoring**: Refactor the code to improve readability and maintainability, ensuring that the streaming logic is modular and easy to update. \n\nExample code for handling streaming responses in Node.js might look like this: \n```javascript\nimport { createReadStream } from 'fs';\nimport axios from 'axios';\n\nconst apiStream = async () => {\n  const response = await axios.get('https://api.deepseek.com/chat/completions', {\n    params: { stream: true },\n    responseType: 'stream'\n  });\n\n  const chunks = [];\n  response.data.on('data', chunk => chunks.push(chunk));\n  response.data.on('end', () => {\n    const fullResponse = Buffer.concat(chunks).toString();\n    console.log(fullResponse);\n  });\n};\n```\n",
        "testStrategy": "1. **Unit Tests**: Write unit tests to verify that the streaming response is correctly buffered and processed without repeated text. Use mocking libraries to simulate API responses. \n2. **Integration Tests**: Conduct integration tests with the OpenRouter/DeepSeek API to ensure the fix works in real-world scenarios. Test with different models and edge cases (e.g., network errors). \n3. **Manual Testing**: Perform manual testing to visually inspect the output for any issues. \n4. **Performance Testing**: Run performance tests to ensure that the buffering mechanism does not introduce significant latency or memory usage issues.",
        "status": "done",
        "dependencies": [
          1,
          2,
          6
        ],
        "priority": "medium",
        "subtasks": []
      },
      {
        "id": 8,
        "title": "Fix Token Usage Tracking for OpenRouter/DeepSeek Models",
        "description": "Update the system to accurately track and display token usage for OpenRouter/DeepSeek models, ensuring usage stats reflect actual tokens consumed.",
        "details": "Investigate the current implementation for tracking token usage with OpenRouter/DeepSeek models, focusing on why token counts are reported as zero. Review the API responses from OpenRouter/DeepSeek to determine if token usage information is returned (e.g., in response metadata or headers). If the API does not provide token usage directly, implement logic to estimate tokens based on the prompt and completion using a compatible tokenizer (such as tiktoken or a DeepSeek-specific tokenizer). Integrate this logic into the model usage stats pipeline, ensuring that token counts are updated and displayed correctly in the UI and any relevant logs or analytics. If using a third-party analytics or logging tool (e.g., Langfuse), ensure custom model definitions are set up to enable token cost tracking, as described in community discussions and documentation. Document any changes to the tracking logic and update configuration or environment variables as needed.",
        "testStrategy": "1. Unit test the token counting logic with a variety of prompts and completions to ensure accuracy. 2. Simulate API responses from OpenRouter/DeepSeek and verify that token usage is correctly parsed or estimated. 3. Perform integration tests to confirm that token usage stats are updated in the UI and logs after model invocations. 4. If using analytics tools, verify that token usage and cost are reported as expected for OpenRouter/DeepSeek models. 5. Conduct regression tests to ensure token tracking for other providers remains unaffected.",
        "status": "done",
        "dependencies": [
          1,
          7
        ],
        "priority": "medium",
        "subtasks": []
      },
      {
        "id": 9,
        "title": "Implement Model Discovery Feature",
        "description": "Add --models CLI flag and /models slash command to display available AI models grouped by provider, showing configuration status and model capabilities",
        "details": "",
        "testStrategy": "",
        "status": "pending",
        "dependencies": [
          6
        ],
        "priority": "high",
        "subtasks": [
          {
            "id": 1,
            "title": "Define IProvider Interface with get_available_models()",
            "description": "Create a new IProvider interface that standardizes model discovery by requiring a get_available_models() method for all providers.",
            "dependencies": [],
            "details": "Design the IProvider interface in the shared provider module. The interface should specify a get_available_models() method that returns a list of model metadata objects, including model name, capabilities, and configuration status.",
            "status": "done",
            "testStrategy": "Write unit tests to ensure that any class implementing IProvider must define get_available_models()."
          },
          {
            "id": 2,
            "title": "Implement get_available_models() for Gemini Provider",
            "description": "Add the get_available_models() method to the Gemini provider, returning all supported models with their metadata and configuration status.",
            "dependencies": [
              1
            ],
            "details": "In the Gemini provider implementation, fetch or define the list of available models. For each model, include metadata such as description, context window, pricing, and configuration status (e.g., API key present).",
            "status": "done",
            "testStrategy": "Test that get_available_models() returns accurate model data and correct status based on configuration."
          },
          {
            "id": 3,
            "title": "Implement get_available_models() for OpenRouter Provider",
            "description": "Add the get_available_models() method to the OpenRouter provider, returning all supported models with their metadata and configuration status.",
            "dependencies": [
              1
            ],
            "details": "In the OpenRouter provider, fetch the model list via API or static config. Include metadata (description, context window, pricing) and check for valid API key to set configuration status.",
            "status": "done",
            "testStrategy": "Test with valid and invalid API keys to verify correct model listing and status reporting."
          },
          {
            "id": 4,
            "title": "Implement get_available_models() for Custom API Provider",
            "description": "Add the get_available_models() method to the Custom API provider, returning all supported models with their metadata and configuration status.",
            "dependencies": [
              1
            ],
            "details": "For the Custom API provider, define how models are discovered (e.g., static config or API call). Return model metadata and indicate if required configuration (e.g., endpoint, key) is present.",
            "status": "done",
            "testStrategy": "Test with various custom API configurations to ensure correct model discovery and status."
          },
          {
            "id": 5,
            "title": "Add --models CLI Argument Parsing",
            "description": "Extend the CLI parser to recognize the --models flag and trigger model discovery logic.",
            "dependencies": [
              2,
              3,
              4
            ],
            "details": "Update the CLI argument parser to handle --models. When invoked, aggregate model lists from all providers using their get_available_models() methods.",
            "status": "pending",
            "testStrategy": "Test CLI with --models flag to ensure it triggers model discovery and handles errors gracefully."
          },
          {
            "id": 6,
            "title": "Create Model Listing Output Formatter",
            "description": "Develop a formatter to display models grouped by provider, showing configuration status, capabilities, and metadata.",
            "dependencies": [
              5
            ],
            "details": "Implement a function to format the aggregated model data. Group models by provider, display configuration status (e.g., ✅/❌), and show metadata such as description, context window, and pricing. Ensure output is readable in both CLI and interactive modes.",
            "status": "pending",
            "testStrategy": "Test output formatting with various provider/model combinations and missing configurations."
          },
          {
            "id": 7,
            "title": "Implement /models Slash Command for Interactive Mode",
            "description": "Add a /models command to the interactive CLI that invokes the model discovery logic and displays formatted output.",
            "dependencies": [],
            "details": "Register the /models command in the interactive CLI. When triggered, call the model discovery logic and display the formatted model list to the user.",
            "status": "pending",
            "testStrategy": "Test /models command in interactive mode for correct output and error handling."
          },
          {
            "id": 8,
            "title": "Add Model Aliases Configuration and Comprehensive Tests",
            "description": "Support model aliases in configuration and create tests covering all aspects of the model discovery feature.",
            "dependencies": [],
            "details": "Allow users to define aliases for models in the config. Update model discovery logic to display aliases. Write tests for interface, provider implementations, CLI flag, slash command, output formatting, and alias handling.",
            "status": "pending",
            "testStrategy": "Write unit and integration tests for alias resolution, model listing, and all user-facing features."
          }
        ]
      },
      {
        "id": 10,
        "title": "Enhance Shell Tool Transparency",
        "description": "Improve ShellTool output to show executed command, exit code, full stdout/stderr, and execution duration for better debugging and user confidence",
        "details": "",
        "testStrategy": "",
        "status": "pending",
        "dependencies": [
          9
        ],
        "priority": "medium",
        "subtasks": [
          {
            "id": 1,
            "title": "Modify ShellTool Return Structure",
            "description": "Update the ShellTool's return structure to include the executed command, exit code, full stdout, and stderr outputs.",
            "dependencies": [],
            "details": "Refactor the ShellTool's execution logic so that every run returns a structured object containing the command string, its exit code, and the complete standard output and error streams.",
            "status": "pending",
            "testStrategy": "Write unit tests to verify that the returned object always includes all required fields with accurate values for various command scenarios."
          },
          {
            "id": 2,
            "title": "Implement Execution Duration Tracking",
            "description": "Add logic to measure and record the duration of each command execution within the ShellTool.",
            "dependencies": [
              1
            ],
            "details": "Integrate timing functionality to capture the start and end time of each command, calculating the total execution duration and including it in the return structure.",
            "status": "pending",
            "testStrategy": "Test with commands of varying lengths to ensure the duration is measured accurately and consistently included in the output."
          },
          {
            "id": 3,
            "title": "Update Output Formatting",
            "description": "Revise the ShellTool's output formatting to clearly display the executed command, exit code, stdout, stderr, and execution duration.",
            "dependencies": [
              2
            ],
            "details": "Design and implement a user-friendly output format that presents all transparency details in a readable and organized manner, suitable for both CLI and potential UI consumption.",
            "status": "pending",
            "testStrategy": "Verify output formatting through snapshot and integration tests, ensuring all fields are present and clearly labeled."
          },
          {
            "id": 4,
            "title": "Add Verbosity Settings",
            "description": "Introduce verbosity settings to allow users to control the level of detail shown in ShellTool output.",
            "dependencies": [
              3
            ],
            "details": "Implement configuration options or command-line flags that let users toggle between minimal and detailed output, affecting which fields are displayed.",
            "status": "pending",
            "testStrategy": "Test all verbosity levels to confirm that output detail matches user settings and that toggling works as expected."
          },
          {
            "id": 5,
            "title": "Create Tests for Enhanced Transparency Features",
            "description": "Develop comprehensive tests to validate all new transparency features and ensure robust, reliable behavior.",
            "dependencies": [
              4
            ],
            "details": "Write unit, integration, and regression tests covering all aspects of the enhanced output, including edge cases and error conditions.",
            "status": "pending",
            "testStrategy": "Automate test execution and require all tests to pass before merging changes, ensuring ongoing reliability."
          }
        ]
      },
      {
        "id": 11,
        "title": "Improve Model Listing with Loading Indicators, Intelligent Organization, and Metadata-Based Summaries",
        "description": "Enhance the model listing feature to display loading indicators, organize models intelligently, and provide helpful summaries and recommendations using OpenRouter's model metadata such as pricing, performance, and use cases.",
        "details": "1. Refactor the model listing UI to show a clear loading indicator while fetching models from OpenRouter, ensuring users are informed of data loading states.\n2. Implement intelligent grouping and sorting of models based on key metadata (e.g., provider, pricing tier, performance benchmarks, recommended use cases). Consider using sections or tabs for major providers or categories.\n3. For each model, display a concise summary panel that highlights pricing, performance metrics, and ideal use cases, leveraging metadata from the OpenRouter API. Use badges or icons for quick visual cues (e.g., 'Best for Coding', 'Low Cost', 'High Accuracy').\n4. Add a recommendation engine that suggests models based on user context or common usage patterns (e.g., if the user often selects coding models, highlight those first).\n5. Ensure accessibility and responsiveness in the updated UI, following existing design patterns.\n6. Update data fetching logic to handle errors gracefully and display appropriate messages if metadata is missing or incomplete.\n7. Refactor or extend the existing ModelSelection component (from Task 3) to incorporate these enhancements, ensuring compatibility with the current model selection and state management flows.",
        "testStrategy": "- Verify that the loading indicator appears during model fetch and disappears once data is loaded.\n- Confirm that models are grouped and sorted as intended, with clear visual separation and accurate metadata display.\n- Check that each model's summary includes pricing, performance, and use case information, and that recommendations are contextually relevant.\n- Test error handling by simulating API failures or missing metadata.\n- Ensure the UI remains accessible and responsive across devices.\n- Perform regression testing to confirm that model selection and configuration continue to work as before.",
        "status": "pending",
        "dependencies": [
          3,
          9
        ],
        "priority": "high",
        "subtasks": []
      }
    ],
    "metadata": {
      "created": "2025-07-07T18:56:28.419Z",
      "updated": "2025-07-17T23:33:24.917Z",
      "description": "Tasks for master context"
    }
  }
}